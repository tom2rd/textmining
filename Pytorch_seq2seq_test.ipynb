{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch-seq2seq-test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tom2rd/textmining/blob/master/Pytorch_seq2seq_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTJpFkMSIlYN",
        "colab_type": "text"
      },
      "source": [
        "#PyTorchによるSeq2seqの実装\n",
        "\n",
        "https://www.pytry3g.com/entry/pytorch-seq2seq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bol98uGHc8pB",
        "colab_type": "text"
      },
      "source": [
        "Google Colab にドライブをマウント"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-ADyQR7IIqb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "f43ae153-8302-4a00-b605-97ad2fc6b3cb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEP5matvdFWq",
        "colab_type": "text"
      },
      "source": [
        "Googlecolabdataというフォルダをマウント"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rM0PRlpzblTm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f18a0b0c-50d6-400f-e699-2180903fe98e"
      },
      "source": [
        "cd drive/My\\ Drive/Googlecolabdata"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Googlecolabdata\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVrbbf3ddMAi",
        "colab_type": "text"
      },
      "source": [
        "Pytorchのインストール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RfTIS0mb0Mx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install torch > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3Yjy4LbdWQh",
        "colab_type": "text"
      },
      "source": [
        "#データの用意"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEaFoZ_OcEvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "word2id = {str(i): i for i in range(10)}\n",
        "word2id.update({\"<pad>\": 10, \"+\": 11, \"<eos>\": 12})\n",
        "id2word = {v: k for k, v in word2id.items()}\n",
        "\n",
        "def load_dataset(N=20000):\n",
        "    def generate_number():\n",
        "        number = [random.choice(list(\"0123456789\")) for _ in range(random.randint(1, 3))] \n",
        "        # a <= N <= b random.randint(a, b)\n",
        "        return int(\"\".join(number))\n",
        "    \n",
        "    def padding(string, training=True):\n",
        "        string = \"{:*<7s}\".format(string) if training else \"{:*<6s}\".format(string)\n",
        "        return string.replace(\"*\", \"<pad>\")\n",
        "    \n",
        "    def transform(string, seq_len=7):\n",
        "        tmp = []\n",
        "        for i, c in enumerate(string):\n",
        "            try:\n",
        "                tmp.append(word2id[c])\n",
        "            except:\n",
        "                tmp += [word2id[\"<pad>\"]] * (seq_len - i)\n",
        "                break\n",
        "        return tmp\n",
        "        \n",
        "    data = []\n",
        "    target = []    \n",
        "    for _ in range(N):\n",
        "        x = generate_number()\n",
        "        y = generate_number()\n",
        "        z = x + y\n",
        "        left = padding(str(x) + \"+\" + str(y))\n",
        "        right = padding(str(z), training=False)\n",
        "        data.append(transform(left))\n",
        "        right = transform(right, seq_len=6)\n",
        "        right = [12] + right[:5]\n",
        "        right[right.index(10)] = 12\n",
        "        target.append(right)\n",
        "        \n",
        "    return data, target\n",
        "\n",
        "data, target = load_dataset()\n",
        "train_x, test_x, train_t, test_t = train_test_split(data, target, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-P7Thy0Jd0If",
        "colab_type": "text"
      },
      "source": [
        "#EncoderとDecoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6wNaH_ycLw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "embedding_dim = 16\n",
        "hidden_dim = 128\n",
        "vocab_size = len(word2id)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, batch_size=100):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=word2id[\"<pad>\"])\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "    def forward(self, indices):\n",
        "        embedding = self.word_embeddings(indices)\n",
        "        if embedding.dim() == 2:\n",
        "            embedding = torch.unsqueeze(embedding, 1)\n",
        "        _, state = self.gru(embedding, torch.zeros(1, self.batch_size, self.hidden_dim, device=device))\n",
        "        \n",
        "        return state\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, batch_size=100):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=word2id[\"<pad>\"])\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.output = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, index, state):\n",
        "        embedding = self.word_embeddings(index)\n",
        "        if embedding.dim() == 2:\n",
        "            embedding = torch.unsqueeze(embedding, 1)\n",
        "        gruout, state = self.gru(embedding, state)\n",
        "        output = self.output(gruout)\n",
        "        return output, state\n",
        "\n",
        "\n",
        "encoder = Encoder(vocab_size, embedding_dim, hidden_dim).to(device)\n",
        "decoder = Decoder(vocab_size, embedding_dim, hidden_dim).to(device)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=word2id[\"<pad>\"])\n",
        "\n",
        "# Initialize opotimizers\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4xLi3Evd9PQ",
        "colab_type": "text"
      },
      "source": [
        "#学習する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gvRBfS8cTnQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "64011353-42f5-46a9-d004-a7a18a6ccf7f"
      },
      "source": [
        "from datetime import datetime\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "batch_size=100\n",
        "def train2batch(data, target, batch_size=100):\n",
        "    input_batch = []\n",
        "    output_batch = []\n",
        "    data, target = shuffle(data, target)\n",
        "    \n",
        "    for i in range(0, len(data), batch_size):\n",
        "        input_tmp = []\n",
        "        output_tmp = []\n",
        "        for j in range(i, i+batch_size):\n",
        "            input_tmp.append(data[j])\n",
        "            output_tmp.append(target[j])\n",
        "        input_batch.append(input_tmp)\n",
        "        output_batch.append(output_tmp)\n",
        "    return input_batch, output_batch\n",
        "\n",
        "def get_current_time():\n",
        "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "\n",
        "print(\"Training...\")\n",
        "n_epoch = 100\n",
        "for epoch in range(1, n_epoch+1):\n",
        "\n",
        "    \n",
        "    input_batch, output_batch = train2batch(train_x, train_t)\n",
        "    for i in range(len(input_batch)):\n",
        "        # Zero gradients\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "        # Prepare tensor\n",
        "        inputs = torch.tensor(input_batch[i], device=device)\n",
        "        outputs = torch.tensor(output_batch[i], device=device)\n",
        "        # Forward pass through encoder\n",
        "        encoder_hidden = encoder(inputs)\n",
        "        # Create source and target\n",
        "        source = outputs[:, :-1]\n",
        "        target = outputs[:, 1:]\n",
        "        decoder_hidden = encoder_hidden\n",
        "        \n",
        "        # Forward batch of sequences through decoder one time step at a time\n",
        "        loss = 0\n",
        "        for i in range(source.size(1)):\n",
        "            decoder_output, decoder_hidden = decoder(source[:, i], decoder_hidden)\n",
        "            decoder_output = torch.squeeze(decoder_output)\n",
        "            loss += criterion(decoder_output, target[:, i])\n",
        "\n",
        "        # Perform backpropagation\n",
        "        loss.backward()\n",
        "        \n",
        "        # Adjust model weights\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "    \n",
        "    if epoch % 10 == 0:\n",
        "        print(get_current_time(), \"Epoch %d: %.2f\" % (epoch, loss.item()))        \n",
        "        \n",
        "    if epoch % 10 == 0:\n",
        "        model_name = \"seq2seq_calculator_v{}.pt\".format(epoch)\n",
        "        torch.save({\n",
        "            'encoder_model': encoder.state_dict(),\n",
        "            'decoder_model': decoder.state_dict(),\n",
        "        }, model_name)\n",
        "        print(\"Saving the checkpoint...\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-2949bbf22276>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# Forward pass through encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mencoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;31m# Create source and target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-477665ffb786>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0m_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_rnn_impls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpermutation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[0;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;31m# type: (Tensor, Tuple[int, int, int], str) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected hidden size (1, 100, 128), got (1, 1, 128)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByE1vK45eEqA",
        "colab_type": "text"
      },
      "source": [
        "#テストする"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLjoBg5PcsDZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "outputId": "b59ea397-4c85-4f5f-e0ae-b87338027057"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "result = \"\"\"---------------\n",
        "Q:{:>10s}\n",
        "A:{:>10s}\n",
        "T/F: {}\n",
        "---------------\"\"\"\n",
        "\n",
        "encoder = Encoder(vocab_size, embedding_dim, hidden_dim, batch_size=1).to(device)\n",
        "decoder = Decoder(vocab_size, embedding_dim, hidden_dim, batch_size=1).to(device)\n",
        "\n",
        "\n",
        "for epoch in range(10, 101, 10):\n",
        "    model_name = \"seq2seq_calculator_v{}.pt\".format(epoch)\n",
        "    checkpoint = torch.load(model_name)\n",
        "    encoder.load_state_dict(checkpoint[\"encoder_model\"])\n",
        "    decoder.load_state_dict(checkpoint[\"decoder_model\"])\n",
        "    \n",
        "    print(\"Checkpoint {:>3d}\".format(epoch))\n",
        "    print(\"-\"*30)\n",
        "    accuracy = 0\n",
        "    with torch.no_grad():\n",
        "        for i in range(len(test_x)):\n",
        "            x = test_x[i]\n",
        "            input_tensor = torch.tensor([x], device=device)\n",
        "            state = encoder(input_tensor)\n",
        "            token = \"<eos>\"\n",
        "            try:\n",
        "                padded_idx_x = x.index(word2id[\"<pad>\"])\n",
        "            except ValueError:\n",
        "                padded_idx_x = len(x)\n",
        "            left = \"\".join(map(lambda c: str(id2word[c]), x[:padded_idx_x]))\n",
        "            right = []\n",
        "            for _ in range(7):\n",
        "                index = word2id[token]\n",
        "                input_tensor = torch.tensor([index], device=device)\n",
        "                output, state = decoder(input_tensor, state)\n",
        "                prob = F.softmax(torch.squeeze(output))\n",
        "                index = torch.argmax(prob.cpu().detach()).item()\n",
        "                token = id2word[index]\n",
        "                if token == \"<eos>\":\n",
        "                    break\n",
        "                right.append(token)\n",
        "            right = \"\".join(right)\n",
        "            flag = [\"F\", \"T\"][eval(left) == int(right)]\n",
        "            #print(result.format(left, right, flag))\n",
        "            if flag == \"T\":\n",
        "                accuracy += 1\n",
        "    print(\"Accuracy: {:.2f}\".format(accuracy / len(test_x)))\n",
        "    print(\"-\"*30)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checkpoint  10\n",
            "------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.31\n",
            "------------------------------\n",
            "Checkpoint  20\n",
            "------------------------------\n",
            "Accuracy: 0.55\n",
            "------------------------------\n",
            "Checkpoint  30\n",
            "------------------------------\n",
            "Accuracy: 0.72\n",
            "------------------------------\n",
            "Checkpoint  40\n",
            "------------------------------\n",
            "Accuracy: 0.75\n",
            "------------------------------\n",
            "Checkpoint  50\n",
            "------------------------------\n",
            "Accuracy: 0.79\n",
            "------------------------------\n",
            "Checkpoint  60\n",
            "------------------------------\n",
            "Accuracy: 0.81\n",
            "------------------------------\n",
            "Checkpoint  70\n",
            "------------------------------\n",
            "Accuracy: 0.83\n",
            "------------------------------\n",
            "Checkpoint  80\n",
            "------------------------------\n",
            "Accuracy: 0.82\n",
            "------------------------------\n",
            "Checkpoint  90\n",
            "------------------------------\n",
            "Accuracy: 0.80\n",
            "------------------------------\n",
            "Checkpoint 100\n",
            "------------------------------\n",
            "Accuracy: 0.83\n",
            "------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}